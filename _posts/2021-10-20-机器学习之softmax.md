---
layout:     post
title:      机器学习篇 | 多分类模型-Softmax
subtitle:   
date:       2021-10-20
author:     Aiden
header-img: img/post-bg-coffee.jpeg
catalog: true 
tags:
    - 机器学习
---

### softmax 模型说明


![image.png]({{ site.url }}/assets/ml_3_1.jpg)

对输入数据 $\lbrace (x_{1}, y_{1}), (x_{2}, y_{2}), ..., (x_{m}, y_{m}) \rbrace$有$k$个类别, 即 $y_{i} \in \lbrace 1, 2, ...,k \rbrace$,
那么 softmax 回归主要估算输入数据 $x_{i}$ 归属于每个类别的概率， 即

![image.png]({{ site.url }}/assets/ml_3_5.jpg)

其中, $\theta_{1}, \theta_{2}, ..., \theta_{k}$ 是模型的参数, 乘 $\frac{1}{ \sum_{j=1}^{k} e^{\theta_{j}^{T}x_{i}} }$ 是为了归一化,
softmax 将输入数据 $x_{i}$ 归属于类别 $j$ 的概率为

$$p(y_{i}=j|x_{i};\theta) = \frac{e^{\theta^{T}_{j}x_{i}}}{\sum_{l=1}^{k}e^{\theta^{T}_{l}x_{i}}}$$

![image.png]({{ site.url }}/assets/ml_3_2.jpg)

对于这个样本的联合分布概率，引入则可以表示为:

![image.png]({{ site.url }}/assets/ml_3_6.jpg)

这里的 $1 \cdot \lbrace y_i=j \rbrace$ 为示性函数, 当 $1{true} = 1$, $1{false} = 0$

引入极大似然函数

![image.png]({{ site.url }}/assets/ml_3_7.jpg)

定义损失函数为:

![image.png]({{ site.url }}/assets/ml_3_8.jpg)

### 梯度下降法

![image.png]({{ site.url }}/assets/ml_3_9.jpg)

使用梯度下降法计算过程为

![image.png]({{ site.url }}/assets/ml_3_10.jpg)

#### 优化方式

$$\theta_{s} := \theta_{s} - \alpha \frac{1}{m} \sum_{i=1}^{m} x_i (1 \cdot \lbrace y_i =s \rbrace - p \lbrace y_i =s | x_i; \theta \rbrace )$$

