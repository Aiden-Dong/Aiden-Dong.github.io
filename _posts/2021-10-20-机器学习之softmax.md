---
layout:     post
title:      机器学习篇 | 多分类模型-Softmax
subtitle:   
date:       2021-10-20
author:     Aiden
header-img: img/post-bg-coffee.jpeg
catalog: true 
tags:
    - 机器学习
---

### softmax 模型说明


![image.png]({{ site.url }}/assets/ml_3_1.jpg)

对输入数据 $\lbrace (x_{1}, y_{1}), (x_{2}, y_{2}), ..., (x_{m}, y_{m}) \rbrace$有$k$个类别, 即 $y_{i} \in \lbrace 1, 2, ...,k \rbrace$,
那么 softmax 回归主要估算输入数据 $x_{i}$ 归属于每个类别的概率， 即

$$h_{\theta}(x_{i}) = \left[
\begin{matrix}
p(y_{i}=1|x_{i};\theta) \\
p(y_{i}=2|x_{i};\theta) \\
... \\
p(y_{i}=k|x_{i};\theta) 
\end{matrix} \right]\tag{2} = \frac{1}{\sum_{j=1}^{k}e^{\theta^{T}_{j}x_{i}}} \left[
\begin{matrix}
e^{\theta^{T}_{1}x_{i}} \\
e^{\theta^{T}_{2}x_{i}} \\
... \\
e^{\theta^{T}_{k}x_{i}} 
\end{matrix} \right]\tag{2}$$


其中, $\theta_{1}, \theta_{2}, ..., \theta_{k}$ 是模型的参数, 乘 $\frac{1}{ \sum_{j=1}^{k} e^{\theta_{j}^{T}x_{i}} }$ 是为了归一化,
softmax 将输入数据 $x_{i}$ 归属于类别 $j$ 的概率为

$$p(y_{i}=j|x_{i};\theta) = \frac{e^{\theta^{T}_{j}x_{i}}}{\sum_{l=1}^{k}e^{\theta^{T}_{l}x_{i}}}$$

上面的式子可以用下图形象化的解析(来自台大李宏毅《一天搞懂深度学习》)。

![image.png]({{ site.url }}/assets/ml_3_2.jpg)